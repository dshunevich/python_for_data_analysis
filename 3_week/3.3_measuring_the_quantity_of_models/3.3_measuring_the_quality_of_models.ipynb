{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики и разбиение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# модуль позволяющий оценить качество работы моделей\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем обучить логистическую регрессию на всех данных и посмотреть acuracy (точность) предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmitriy.shunevich\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "logistic_regression = LogisticRegression()\n",
    "model = logistic_regression.fit(cancer.data, cancer.target)\n",
    "\n",
    "print('Acuracy: {:.2f}'.format(model.score(cancer.data, cancer.target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличим параметр `max_iter` до 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "logistic_regression = LogisticRegression(max_iter=10000)\n",
    "model = logistic_regression.fit(cancer.data, cancer.target)\n",
    "\n",
    "print('Acuracy: {:.2f}'.format(model.score(cancer.data, cancer.target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество достаточно неплохое, однако мы обучаемся на всех данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.96\n",
      "ROC AUC: 0.95\n",
      "F1: 0.97\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(cancer.data)\n",
    "\n",
    "print('Acuracy: {:.2f}'.format(metrics.accuracy_score(cancer.target, predictions)))\n",
    "print('ROC AUC: {:.2f}'.format(metrics.roc_auc_score(cancer.target, predictions)))\n",
    "print('F1: {:.2f}'.format(metrics.f1_score(cancer.target, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаться на всех данных не очень хорошая практика, так как мы не можем достоверно оценить как модель будет вести себя на каких-то новых данных.  \n",
    "Для этого нам может помочь модуль `sklearn.model_selection` и функция `train_test_split`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас `x_train, y_train` - это выборки на которых мы обучаемся  \n",
    "`x_test, y_test` - это выборки на которых мы оцениваем качество модели на объектах новой выборки, которую модель еще не видела чтобы понять как наша модель выучила природную зависимость.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.96\n",
      "Test accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target,\n",
    "    test_size=0.2, random_state=12    \n",
    ")\n",
    "\n",
    "# передаем тренировочные объекты (примерно 80% из нашей выборки)\n",
    "model = logistic_regression.fit(x_train, y_train)\n",
    "\n",
    "print('Train accuracy: {:.2f}'.format(model.score(x_train, y_train)))\n",
    "print('Test accuracy: {:.2f}'.format(model.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим как можно сделать тоже самое, только для задачи регрессии. Посмотрим на другие возможности линейной регрессии. Импортируем из модуля `sklearn.linear_model` три класса `Lasso, Ridge, ElasticNet`, которые представляют из себя линейную регрессию с различными регуляризациями.  \n",
    "\n",
    "`Lasso` - это L1 регуляризация, когда мы добавляем в функцию ошибки первую норму весов. Т.е. мы добавляем к нашей функции сумму модулей весов.  \n",
    "`Ridge` - это L2 регуляризация, гребневая регрессия, которая добавляет сумму квадратов весов.  \n",
    "`ElasticNet` - L1 и L2 регуляризация в одном.\n",
    "\n",
    "Ниже в цикле мы обучим все три модели и посмотрим на MSE (среднеквадратичную ошибку). Обучаемся на 80% данных и на 20% данных тестируем нашу модель. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._coordinate_descent.Lasso'>\n",
      "MSE: 0.14\n",
      "\n",
      "<class 'sklearn.linear_model._ridge.Ridge'>\n",
      "MSE: 0.07\n",
      "\n",
      "<class 'sklearn.linear_model._coordinate_descent.ElasticNet'>\n",
      "MSE: 0.10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "lasso = Lasso()\n",
    "ridge = Ridge()\n",
    "elastic = ElasticNet()\n",
    "\n",
    "for model in [lasso, ridge, elastic]:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            cancer.data, cancer.target,\n",
    "            test_size=0.2\n",
    "        )\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        predictions = model.predict(x_test)\n",
    "        print(model.__class__)\n",
    "        print('MSE: {:.2f}\\n'.format(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из результатов - лучше всего предсказывает гребневая регрессия. В данном случае она показала MSE чуть ниже чем остальные функции.  \n",
    "\n",
    "Так же можно работать с другими функциями из модуля `metrics`, например  \n",
    "`R2 score` - возвращает коэффициент детерминации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.57\n",
      "R2: 0.57\n"
     ]
    }
   ],
   "source": [
    "print('R2: {:.2f}'.format(model.score(x_test, y_test)))\n",
    "print('R2: {:.2f}'.format(metrics.r2_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть еще один полезный подход - чтобы не откладывать какой-то набор в черный ящик(для тестирования), а использовать все данные, но при этом знать что наша модель не переобучается. Это называется кросс-валидацией. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кросс-валидация "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`KFold` - класс, который позволяет делать кросс-валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Vi\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR[:475])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть три класса: \n",
    "    - Iris-Setosa\n",
    "    - Iris-Versicolour\n",
    "    - Iris-Vi\n",
    "\n",
    "И по характеристикам:\n",
    "    - sepal length in cm\n",
    "    - sepal width in cm\n",
    "    - petal length in cm\n",
    "    - petal width in cm\n",
    "    \n",
    "Нам необходимо предсказать к какому классу относится цветок (0, 1, 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать эту задачу с помощью логистической регрессии, потому что это задача классификации. \n",
    "\n",
    "Выборка разбивается на блоки (в данном случае на 5 блоков) и первые 4 блока используются для того чтобы обучить нашу модель, а 5ый блок используется для того чтобы оценить качество нашей модели. Потом следующие 4 + 1 блоков и так далее. В цикле итерируемся по разным разбиениям. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим что представляет из себя `iris.data` (`numpy.ndarray`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([2, 3, 4, 5, 6, 7, 8, 9]), array([0, 1]))\n",
      "(array([0, 1, 4, 5, 6, 7, 8, 9]), array([2, 3]))\n",
      "(array([0, 1, 2, 3, 6, 7, 8, 9]), array([4, 5]))\n",
      "(array([0, 1, 2, 3, 4, 5, 8, 9]), array([6, 7]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([8, 9]))\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5) # +StratifiedKFold\n",
    "\n",
    "for i in cv.split(iris.data[:10]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0 Score 1.00\n",
      "Split 1 Score 1.00\n",
      "Split 2 Score 0.87\n",
      "Split 3 Score 0.93\n",
      "Split 4 Score 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmitriy.shunevich\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\dmitriy.shunevich\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "cv = KFold(n_splits=5) # +StratifiedKFold\n",
    "\n",
    "for split_idx, (train_idx, test_idx) in enumerate(cv.split(iris.data)):\n",
    "    x_train, x_test = iris.data[train_idx], iris.data[test_idx]\n",
    "    y_train, y_test = iris.target[train_idx], iris.target[test_idx]\n",
    "    \n",
    "    logistic_regression.fit(x_train, y_train)\n",
    "    score = logistic_regression.score(x_test, y_test)\n",
    "    print('Split {} Score {:.2f}'.format(split_idx, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим `max_iter=1000` чтобы не возникало предупреждение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0 Score 1.00\n",
      "Split 1 Score 1.00\n",
      "Split 2 Score 0.87\n",
      "Split 3 Score 0.93\n",
      "Split 4 Score 0.83\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "cv = KFold(n_splits=5) # +StratifiedKFold\n",
    "\n",
    "for split_idx, (train_idx, test_idx) in enumerate(cv.split(iris.data)):\n",
    "    x_train, x_test = iris.data[train_idx], iris.data[test_idx]\n",
    "    y_train, y_test = iris.target[train_idx], iris.target[test_idx]\n",
    "    \n",
    "    logistic_regression.fit(x_train, y_train)\n",
    "    score = logistic_regression.score(x_test, y_test)\n",
    "    print('Split {} Score {:.2f}'.format(split_idx, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть \"хорошие\" разбиения, есть \"плохие\" разбиения. Логичным вариантом будет просто взять усредненное значение всех `score`.  \n",
    "Теперь посмотрим как сделать кросс-валидацию автоматически без ручного присваивания индексов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val scoreL [1.         1.         0.86666667 0.93333333 0.83333333]\n",
      "Mean cross val score: 0.93\n"
     ]
    }
   ],
   "source": [
    "cv_score = cross_val_score(\n",
    "    logistic_regression, iris.data, iris.target,\n",
    "    scoring='accuracy', cv=cv\n",
    ")\n",
    "\n",
    "print('Cross val scoreL {}'.format(cv_score))\n",
    "\n",
    "# усредним наши полученные значения\n",
    "print('Mean cross val score: {:.2f}'.format(cv_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть наше среднее качество на кросс-валидации = 0.93"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
